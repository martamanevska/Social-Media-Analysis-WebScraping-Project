{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Social Media Analytics\n",
    "### Introduction to Text Mining\n",
    "## Text Annotation\n",
    "(c) Nuno Antonio 2019-2022 v1.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk \n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3q/yw7kv53d5mlb0smm2tg9nkgr0000gn/T/ipykernel_53335/375977262.py:5: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  ds = pd.DataFrame(pd.read_csv(\"HotelOnlineReviews.txt\",sep=\"|\",\n",
      "b'Skipping line 12799: expected 21 fields, saw 23\\n'\n",
      "b'Skipping line 37247: expected 21 fields, saw 22\\n'\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dtypes = {'RevID':'category','Source':'category','HotelID':'category',\n",
    "  'HotelType':'category','HotelStars':'category','ObsDateGlobalRating':'float64',\n",
    "  'Language':'category','RevUserName':'category','RevUserLocation':'category','RevOverallRating':'float64'}\n",
    "ds = pd.DataFrame(pd.read_csv(\"HotelOnlineReviews.txt\",sep=\"|\", \n",
    "  error_bad_lines=False, dtype=dtypes, decimal=',', index_col='RevID'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing\n",
    "def textPreProcess(rawText, removeHTML=True, charsToRemove = r'\\?|\\.|\\!|\\;|\\.|\\\"|\\,|\\(|\\)|\\&|\\:|\\-', removeNumbers=True, removeLineBreaks=False, specialCharsToRemove = r'[^\\x00-\\xfd]', convertToLower=True, removeConsecutiveSpaces=True):\n",
    "    if type(rawText) != str:\n",
    "        return rawText\n",
    "    procText = rawText\n",
    "        \n",
    "    # Remove HTML\n",
    "    if removeHTML:\n",
    "        procText = BeautifulSoup(procText,'html.parser').get_text()\n",
    "\n",
    "    # Remove punctuation and other special characters\n",
    "    if len(charsToRemove)>0:\n",
    "        procText = re.sub(charsToRemove,' ',procText)\n",
    "\n",
    "    # Remove numbers\n",
    "    if removeNumbers:\n",
    "        procText = re.sub(r'\\d+',' ',procText)\n",
    "\n",
    "    # Remove line breaks\n",
    "    if removeLineBreaks:\n",
    "        procText = procText.replace('\\n',' ').replace('\\r', '')\n",
    "\n",
    "    # Remove special characters\n",
    "    if len(specialCharsToRemove)>0:\n",
    "        procText = re.sub(specialCharsToRemove,' ',procText)\n",
    "\n",
    "    # Normalize to lower case\n",
    "    if convertToLower:\n",
    "        procText = procText.lower() \n",
    "\n",
    "    # Replace multiple consecutive spaces with just one space\n",
    "    if removeConsecutiveSpaces:\n",
    "        procText = re.sub(' +', ' ', procText)\n",
    "\n",
    "    return procText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize words\n",
    "def tokenize_words(words):\n",
    "    if (type(words) != str) or (word_tokenize(words) == ''):\n",
    "        return np.nan\n",
    "    else:\n",
    "        return word_tokenize(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nunoantonio/opt/anaconda3/lib/python3.8/site-packages/bs4/__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create a dataframe with only the description\n",
    "processedReviews =  pd.DataFrame(data=ds.RevDescription.apply(textPreProcess).values, index=ds.index, columns=['PreProcessedText']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize text\n",
    "processedReviews['Words'] =  processedReviews['PreProcessedText'].apply(tokenize_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('we', 'PRP'), ('stayed', 'VBD'), ('nights', 'NNS'), ('at', 'IN'), ('this', 'DT'), ('resort', 'NN'), ('in', 'IN'), ('july/august', 'NN'), ('we', 'PRP'), ('stayed', 'VBD'), ('in', 'IN'), ('a', 'DT'), ('suitte', 'NN'), ('appartment', 'NN'), ('which', 'WDT'), ('was', 'VBD'), ('very', 'RB'), ('nice', 'JJ'), ('the', 'DT'), ('appartment', 'NN'), ('had', 'VBD'), ('two', 'CD'), ('floors', 'NNS'), ('and', 'CC'), ('everything', 'NN'), ('needed', 'VBN'), ('for', 'IN'), ('a', 'DT'), ('nice', 'JJ'), ('vacation', 'NN'), ('the', 'DT'), ('staff', 'NN'), ('was', 'VBD'), ('friendly', 'RB'), ('and', 'CC'), ('service', 'VB'), ('good', 'JJ'), ('at', 'IN'), ('this', 'DT'), ('buy', 'NN'), ('time', 'NN'), ('of', 'IN'), ('year', 'NN'), ('we', 'PRP'), ('found', 'VBD'), ('the', 'DT'), ('common', 'JJ'), ('area', 'NN'), ('with', 'IN'), ('pools', 'NNS'), ('etc', 'VBP'), ('a', 'DT'), ('little', 'JJ'), ('bit', 'NN'), ('to', 'TO'), ('small', 'JJ'), ('and', 'CC'), ('crowded', 'VBD'), ('the', 'DT'), ('gym', 'NN'), ('could', 'MD'), ('not', 'RB'), ('really', 'RB'), ('be', 'VB'), ('called', 'VBN'), ('a', 'DT'), ('gym', 'NN'), ('and', 'CC'), ('two', 'CD'), ('people', 'NNS'), ('inside', 'IN'), ('there', 'EX'), ('was', 'VBD'), ('a', 'DT'), ('crowd', 'NN'), ('having', 'VBG'), ('said', 'VBD'), ('that', 'IN'), ('we', 'PRP'), ('liked', 'VBD'), ('the', 'DT'), ('resort', 'NN'), ('both', 'DT'), ('the', 'DT'), ('location', 'NN'), ('and', 'CC'), ('the', 'DT'), ('quality', 'NN'), ('of', 'IN'), ('the', 'DT'), ('buildings', 'NNS'), ('we', 'PRP'), ('never', 'RB'), ('tried', 'VBD'), ('the', 'DT'), ('restaurant', 'NN'), ('as', 'IN'), ('we', 'PRP'), ('like', 'VBP'), ('to', 'TO'), ('seek', 'VB'), ('up', 'RP'), ('local', 'JJ'), ('restaurants', 'NNS'), ('and', 'CC'), ('also', 'RB'), ('some', 'DT'), ('favorites', 'NNS'), ('in', 'IN'), ('the', 'DT'), ('area', 'NN'), ('the', 'DT'), ('resort', 'NN'), ('is', 'VBZ'), ('close', 'RB'), ('to', 'TO'), ('my', 'PRP$'), ('favorite', 'JJ'), ('restaurant', 'NN'), ('in', 'IN'), ('carvoeiro', 'NN'), ('bon', 'NN'), ('bon', 'NN'), ('restaurant', 'NN'), ('carvoeiro', 'NN'), ('village', 'NN'), ('is', 'VBZ'), ('very', 'RB'), ('nice', 'JJ'), ('with', 'IN'), ('a', 'DT'), ('lot', 'NN'), ('of', 'IN'), ('good', 'JJ'), ('restaurant', 'NN'), ('and', 'CC'), ('in', 'IN'), ('the', 'DT'), ('most', 'RBS'), ('pictures', 'NNS'), ('area', 'NN'), ('of', 'IN'), ('the', 'DT'), ('algarve', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "# ENGLISH POS Tagg - Using NLTK\n",
    "tags = nltk.pos_tag(processedReviews.Words['T4617'])\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nights', 'resort', 'july/august', 'suitte', 'appartment', 'appartment', 'floors', 'everything', 'vacation', 'staff', 'buy', 'time', 'year', 'area', 'pools', 'bit', 'gym', 'gym', 'people', 'crowd', 'resort', 'location', 'quality', 'buildings', 'restaurant', 'restaurants', 'favorites', 'area', 'resort', 'restaurant', 'carvoeiro', 'bon', 'bon', 'restaurant', 'carvoeiro', 'village', 'lot', 'restaurant', 'pictures', 'area', 'algarve']\n"
     ]
    }
   ],
   "source": [
    "# Filter only Nouns\n",
    "nouns = []\n",
    "for tag in tags:\n",
    "    if tag[1][0]==\"N\":  # if if starts with a \"N\"\n",
    "        nouns.append(tag[0])\n",
    "print(nouns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el DET\n",
      "enclave NOUN\n",
      "del ADP\n",
      "hotel NOUN\n",
      "es AUX\n",
      "tan ADV\n",
      "espectacular ADJ\n",
      "que SCONJ\n",
      "las DET\n",
      "vistas NOUN\n",
      "quitan AUX\n",
      "la DET\n",
      "respiración NOUN\n",
      "la DET\n",
      "piscina NOUN\n",
      "es AUX\n",
      "una DET\n",
      "auténtica ADJ\n",
      "gozada ADJ\n",
      "las DET\n",
      "habitaciones NOUN\n",
      "son VERB\n",
      "grandes ADJ\n",
      "y CCONJ\n",
      "tranquilas ADJ\n",
      "lo PRON\n",
      "que SCONJ\n",
      "las PRON\n",
      "hace AUX\n",
      "cómodas ADJ\n",
      "pero CCONJ\n",
      "la DET\n",
      "decoración NOUN\n",
      "y CCONJ\n",
      "los DET\n",
      "baños NOUN\n",
      "están VERB\n",
      "realmente ADV\n",
      "anticuados ADJ\n",
      "el DET\n",
      "desayuno NOUN\n",
      "nos PRON\n",
      "resultó VERB\n",
      "un DET\n",
      "poco ADV\n",
      "decepcionante ADJ\n",
      "no ADV\n",
      "por ADP\n",
      "la DET\n",
      "cantidad NOUN\n",
      "sino CCONJ\n",
      "por ADP\n",
      "la DET\n",
      "calidad NOUN\n",
      "todo PRON\n",
      "es AUX\n",
      "bastante ADV\n",
      "corriente ADJ\n",
      "y CCONJ\n",
      "sorprende VERB\n",
      "por ADP\n",
      "ejemplo NOUN\n",
      "tener VERB\n",
      "solo ADV\n",
      "un DET\n",
      "tipo NOUN\n",
      "de ADP\n",
      "queso NOUN\n",
      "cuando SCONJ\n",
      "hasta ADV\n",
      "en ADP\n",
      "el DET\n",
      "supermercado NOUN\n",
      "te PRON\n",
      "desborda VERB\n",
      "la DET\n",
      "variedad NOUN\n",
      "de ADP\n",
      "quesos NOUN\n",
      "de ADP\n",
      "la DET\n",
      "zona NOUN\n",
      "y CCONJ\n",
      "patés VERB\n"
     ]
    }
   ],
   "source": [
    "# SPANNISH POS Tagg - Using Spacy\n",
    "import spacy    # May require installation\n",
    "nlp = spacy.load(\"es_core_news_sm\") # Load language model (python -m spacy download es_core_news_sm). More models in https://spacy.io/models\n",
    "result = nlp(processedReviews.PreProcessedText['T7883'])\n",
    "for token in result:\n",
    "  print(token, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[espectacular, auténtica, gozada, grandes, tranquilas, cómodas, anticuados, decepcionante, corriente]\n"
     ]
    }
   ],
   "source": [
    "# Filter only Adjectives\n",
    "adjectives = []\n",
    "for token in result:\n",
    "    if token.pos_==\"ADJ\":\n",
    "        adjectives.append(token)\n",
    "print(adjectives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Portuguese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "é AUX\n",
      "um DET\n",
      "hotel NOUN\n",
      "bastante ADV\n",
      "bom ADJ\n",
      "para ADP\n",
      "famílias NOUN\n",
      "com ADP\n",
      "crianças NOUN\n",
      "as DET\n",
      "moradias NOUN\n",
      "individuais ADJ\n",
      "permitem VERB\n",
      "estar AUX\n",
      "mais DET\n",
      "vontade NOUN\n",
      "e CCONJ\n",
      "assim ADV\n",
      "gozar VERB\n",
      "mais ADV\n",
      "os DET\n",
      "espaço NOUN\n",
      "é AUX\n",
      "um DET\n",
      "pouco ADV\n",
      "afastado VERB\n",
      "da DET\n",
      "praia NOUN\n",
      "mas CCONJ\n",
      "compensa VERB\n",
      "pela DET\n",
      "calma NOUN\n",
      "e CCONJ\n",
      "sossego VERB\n",
      "o DET\n",
      "pessoal NOUN\n",
      "é AUX\n",
      "muito ADV\n",
      "agradável ADJ\n",
      "e CCONJ\n",
      "prestável ADJ\n",
      "a DET\n",
      "comida NOUN\n",
      "é AUX\n",
      "boa ADJ\n",
      "e CCONJ\n",
      "as DET\n",
      "acomodações NOUN\n",
      "modernas ADJ\n",
      "tem VERB\n",
      "apenas ADV\n",
      "um NUM\n",
      "senão ADV\n",
      "o DET\n",
      "barulho NOUN\n",
      "das DET\n",
      "rãs ADV\n",
      "durante ADP\n",
      "a DET\n",
      "noite NOUN\n"
     ]
    }
   ],
   "source": [
    "# PORTUGUESE POS Tagg - Using Spacy\n",
    "nlp = spacy.load(\"pt_core_news_sm\")           # Load language model (python -m spacy download pt_core_news_sm). More models in https://spacy.io/models\n",
    "result = nlp(processedReviews.PreProcessedText['T4914'])\n",
    "for token in result:\n",
    "  print(token, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[permitem, gozar, afastado, compensa, sossego, tem]\n"
     ]
    }
   ],
   "source": [
    "# Filter only Verbs\n",
    "verbs = []\n",
    "for token in result:\n",
    "    if token.pos_==\"VERB\":\n",
    "        verbs.append(token)\n",
    "print(verbs)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d7a18bc08bf6b314cad8b0dd8f53415ad78d1015cc806d14e4873c235fb4e191"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
